#!/usr/bin/env python3
# Copyright (C) 2021 Humanitarian OpenStreetmap Team

# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU Affero General Public License as
# published by the Free Software Foundation, either version 3 of the
# License, or (at your option) any later version.

# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU Affero General Public License for more details.

# You should have received a copy of the GNU Affero General Public License
# along with this program.  If not, see <https://www.gnu.org/licenses/>.

# Humanitarian OpenStreetmap Team
# 1100 13th Street NW Suite 800 Washington, D.C. 20005
# <info@hotosm.org>
import argparse
import datetime
import os
import subprocess
import sys
import time
from multiprocessing import Pool
from os.path import exists
from urllib.parse import urlparse

import requests
import wget
from login import verify_me_osm


def parse_arguments():
    parser = argparse.ArgumentParser()
    parser.add_argument(
        "--source", type=str, nargs="+", help="Data source link or file path"
    )
    args = [
        ("PGHOST", "--host", "DB host"),
        ("PGPORT", "--port", "DB port"),
        ("PGUSER", "--user", "DB user"),
        ("PGPASSWORD", "--password", "DB password"),
        ("PGDATABASE", "--database", "DB name"),
    ]

    for env, arg, help_text in args:
        default = os.getenv(env)
        parser.add_argument(
            arg, type=str, help=help_text, default=default, required=(not default)
        )

    parser.add_argument(
        "--include_ref",
        default=False,
        action="store_true",
        help="Include ref in output tables",
    )
    parser.add_argument(
        "--fq",
        type=str,
        choices=["d", "w", "m", "h"],
        default="d",
        help="Field update frequency for updating country during insert , default is daily",
    )
    parser.add_argument(
        "--replication",
        default=False,
        action="store_true",
        help="Prepare tables for replication and Runs Replication",
    )
    parser.add_argument(
        "--flat_nodes",
        type=str,
        help="flat-nodes option of osm2pgsql for import , Takes Filename eg : data/nodes.bin",
    )
    parser.add_argument(
        "--cache",
        type=int,
        help="cache option of osm2pgsql for import takes cache size",
    )

    parser.add_argument(
        "--run_minutely",
        default=False,
        action="store_true",
        help="Runs replication every minute",
    )
    parser.add_argument(
        "--country",
        nargs="+",
        type=int,
        help="id of the country , if you are loading country , it will filter replication data",
    )
    parser.add_argument(
        "--insert",
        action="store_true",
        help="Run osm2pgsql to insert data , Initial Creation Step",
    )
    parser.add_argument(
        "--update",
        action="store_true",
        help="Run Update on table fields for country info",
    )

    parser.add_argument(
        "--download_dir", type=str, help="The directory to download the source file to"
    )
    parser.add_argument(
        "--post_index",
        default=False,
        action="store_true",
        help="Run Post index only on table",
    )
    return parser.parse_args()


def is_local(url):
    url_parsed = urlparse(url)
    if url_parsed.scheme in ("file", ""):  # Possibly a local file
        return exists(url_parsed.path)
    return False


def run_subprocess_cmd(cmd):
    try:
        subprocess.check_output(cmd, env=os.environ)

    except subprocess.CalledProcessError as ex:
        print(ex.output)
        raise ex


def run_replication_cmd(cmd):
    try:
        subprocess.check_output(cmd, env=os.environ, timeout=3600)  # timeout of 1 hour
    except subprocess.CalledProcessError as ex:
        print(ex.output)  # Don't raise error keep the process trying


def run_subprocess_cmd_parallel(cmds):

    with Pool(processes=len(cmds)) as pool:
        pool.map(run_subprocess_cmd, cmds)


def download_file(download_dir, source_path):
    filename = os.path.basename(source_path)
    target_path = os.path.join(download_dir, filename)
    if not os.path.exists(target_path):
        print(f"\nStarting download for: {target_path}")
        if os.environ["OSM_USERNAME"] and os.environ["OSM_PASSWORD"]:
            cookies = verify_me_osm(
                os.environ["OSM_USERNAME"], os.environ["OSM_PASSWORD"]
            )
            if cookies:
                print("Authenticated")
            cookies_fmt = {}
            test = cookies.split("=")
            cookies_fmt[test[0]] = f'{test[1]}=="'
            session = requests.Session()

            # Set the cookies
            session.cookies.update(cookies_fmt)
            response = session.get(source_path, stream=True)

            if response.status_code == 200:
                with open(target_path, "wb") as f:
                    for chunk in response.iter_content(chunk_size=8192):
                        f.write(chunk)

        else:
            response = wget.download(source_path, target_path)
    return target_path


if __name__ == "__main__":

    args = parse_arguments()

    os.environ["PGHOST"] = args.host
    os.environ["PGPORT"] = args.port
    os.environ["PGUSER"] = args.user
    os.environ["PGPASSWORD"] = args.password
    os.environ["PGDATABASE"] = args.database
    start_time = time.time()

    working_dir = os.path.realpath(os.path.dirname(__file__))
    lua_path = (
        os.path.join(working_dir, "raw_with_ref.lua")
        if args.include_ref
        else os.path.join(working_dir, "raw.lua")
    )
    if not args.source:
        source_paths = [os.path.join(working_dir, "sample_data/pokhara_all.osm.pbf")]
    else:
        source_paths = args.source

    download_dir = (
        args.download_dir if args.download_dir else os.path.join(working_dir, "data")
    )
    if not os.path.exists(download_dir):
        os.makedirs(download_dir)

    target_paths = []
    for source_path in source_paths:
        if not os.path.isfile(source_path):
            target_paths.append(download_file(download_dir, source_path))
        else:
            target_paths.append(source_path)
    if len(target_paths) > 1:
        merg_file_path = os.path.join(download_dir, "merged_data.pbf")
        if not os.path.exists(merg_file_path):
            print(f"\nMerging OSM files : {target_paths}")
            cmd = [
                "osmium",
                "merge",
                *target_paths,
                "-o",
                os.path.join(download_dir, "merged_data.pbf"),
            ]
            subprocess.run(cmd, check=True)
        source_path = merg_file_path
    else:
        source_path = target_paths[0]

    if args.insert:
        osm2pgsql = [
            "osm2pgsql",
            "--create",
            "--slim",
            "--extra-attributes",
            "--output=flex",
            "--style",
            lua_path,
            source_path,
        ]
        if args.flat_nodes:
            osm2pgsql.append("--flat-nodes")
            osm2pgsql.append(args.flat_nodes)

        if args.cache:
            osm2pgsql.append("--cache")
            osm2pgsql.append(args.flat_nodes)

        if not args.replication:
            osm2pgsql.append("--drop")
        run_subprocess_cmd(osm2pgsql)

        basic_index_cmd = [
            "psql",
            "-a",
            "-f",
            os.path.join(working_dir, "sql/pre_indexes.sql"),
        ]
        run_subprocess_cmd(basic_index_cmd)

        country_table = [
            "psql",
            "-a",
            "-f",
            os.path.join(working_dir, "sql/countries.sql"),
        ]
        run_subprocess_cmd(country_table)

        if args.replication:  # initialize replication
            replication_init = [
                "python",
                os.path.join(working_dir, "replication"),
                "init",
            ]
            run_subprocess_cmd(replication_init)

    if args.update or args.insert:

        tables = ["nodes", "ways_poly", "ways_line", "relations"]

        current_year = datetime.datetime.now().year
        for table in tables:
            print(table)
            update_cmd_list = []
            for year in range(current_year, 2007, -1):
                # Calculate the start and end dates for this year
                start_date = datetime.datetime(year, 1, 1).strftime("%Y-%m-%d")
                end_date = datetime.datetime.now().strftime("%Y-%m-%d")
                if year != current_year:
                    end_date = datetime.datetime(year + 1, 1, 1).strftime("%Y-%m-%d")

                # Create the command for this year
                cmd = [
                    "python",
                    os.path.join(working_dir, "field_update"),
                    "--target_table",
                    table,
                    "--target_column",
                    "country",
                    "--target_geom",
                    "geom",
                    "--source_table",
                    "countries",
                    "--source_column",
                    "id",
                    "--source_geom",
                    "geometry",
                    "--type",
                    "array",
                    "--f",
                    args.fq,
                    "--end",
                    start_date,
                ]

                if year != current_year:
                    cmd.extend(["--start", end_date])
                update_cmd_list.append(cmd)
            if len(update_cmd_list) > 0:
                run_subprocess_cmd_parallel(update_cmd_list)

    if args.insert or args.post_index:
        ## build post indexes
        basic_index_cmd = [
            "psql",
            "-a",
            "-f",
            os.path.join(working_dir, "sql/post_indexes.sql"),
        ]
        run_subprocess_cmd(basic_index_cmd)
        print(
            f"\nProcess Finished.  Total time taken : {str(datetime.timedelta(seconds=(time.time() - start_time)))}"
        )
    if args.replication:
        print("Starting Replication")

        replication_cmd = [
            "python",
            os.path.join(working_dir, "replication"),
            "update",
            "-s",
            "raw.lua",
            "--max-diff-size",
            "10",
        ]
        if args.country:
            replication_cmd.extend(["--country"])
            replication_cmd.extend([str(x) for x in args.country])
        run_subprocess_cmd(replication_cmd)
        if args.run_minutely:
            while True:  # run replication forever
                # --max-diff-size 10 mb as default
                start = time.time()
                run_replication_cmd(replication_cmd)
                if (time.time() - start) < 60:
                    time.sleep(60)
